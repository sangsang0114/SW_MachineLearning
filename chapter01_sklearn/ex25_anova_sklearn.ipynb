{"cells":[{"cell_type":"markdown","metadata":{"id":"i96WZopjy8SC"},"source":["#### sample data 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V6VE4EU7y8SE"},"outputs":[],"source":["from sklearn.datasets import load_breast_cancer\n","from sklearn.feature_selection import SelectPercentile, f_classif\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","cancer = load_breast_cancer()  #1. sample data load\n","\n","#2.난수로 임의로 생성한 독립변수 50개 추가!!!\n","#    -이 변수들은 종속변수와의 연관성이 높지 않을 것이며\n","#     회귀 또는 분류 모델의 성능(정확도)를 떨어 뜨릴것입니다.\n","#    - P value를 구해 연관성이 낮은 변수를 제거하는 sklearn의 함수를 실습합니다.\n","\n","# 고정된 난수를 발생시킵니다\n","rng = np.random.RandomState(42)\n","noise = rng.normal(size=(len(cancer.data), 50) )\n","\n","# 원본 데이터에 노이즈 변수을 추가합니다\n","# 처음 30개는 원본(cancer.data) 특성이고 다음 50개(noise)는 노이즈입니다\n","X_w_noise = np.hstack([cancer.data, noise])   # cancer.data : 암을 진단 시 사용될 수 있는 다양한 검진정보"]},{"cell_type":"markdown","metadata":{"id":"uphChS-Fy8SF"},"source":["#### 훈련 데이터와 테스트 전용 데이터로 나누기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_sdrfln_y8SF"},"outputs":[],"source":["X_train, X_test, y_train, y_test =  #TODO (\n","    X_w_noise, cancer.target, random_state=0 )\n","                            # random_state=0 (랜덤하게 분리되는 것을 고정), test_size=.5 (50%를 테스트전용데이터로 )"]},{"cell_type":"markdown","metadata":{"id":"CowFAQo6y8SG"},"source":["#### p value 값을 기준으로 연관성이 높은 특성만 선택"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqcUqMnRy8SG","outputId":"a5b245f1-020e-4178-b57a-200a5781a73c"},"outputs":[{"name":"stdout","output_type":"stream","text":["원본 X_train.shape: (426, 80)\n","X_train_selected.shape: (426, 40)\n","원본 X_test.shape: (143, 80)\n","X_test_selected.shape: (143, 40)\n"]}],"source":["\n","# f_classif(기본값)와 SelectPercentile을 사용하여 특성의 50%를 선택합니다\n","select = #TODO  (score_func=f_classif, #TODO ) #F 검정\n","select.#TODO(X_train, y_train)\n","\n","# 훈련 데이터에 적용합니다\n","X_train_selected = #TODO(X_train)\n","\n","print(\"원본 X_train.shape:\", X_train.shape)\n","print(\"X_train_selected.shape:\", X_train_selected.shape)\n","\n","\n","# 테스트 데이터에 적용합니다\n","X_test_selected = #TODO(X_test)\n","\n","print(\"원본 X_test.shape:\", X_test.shape)\n","print(\"X_test_selected.shape:\", X_test_selected.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"swqTbWtRy8SG"},"source":["#### 선택된 특성을 True로 출력"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2eMeXRlYy8SH","outputId":"c3c55f83-7556-4dfa-bf59-bc16b31f06c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ True  True  True  True  True  True  True  True  True False  True False\n","  True  True  True  True  True  True False False  True  True  True  True\n","  True  True  True  True  True  True False  True False  True False  True\n"," False False False  True False False False  True False False False False\n"," False False False  True False  True False False False False False False\n","  True False False False False False  True  True False False False  True\n","  True  True False  True False False False False]\n"]}],"source":["mask = #TODO\n","#선택된 특성을 True로 출력해봅니다. (True로 출력된 열은 선택, False로 출력된 열은 선택되지 않는다.)\n","print(mask)"]},{"cell_type":"markdown","metadata":{"id":"FCt1XvsVy8SH"},"source":["#### 분류 성능 평가"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2oz8eXB1y8SH","outputId":"ce4f0043-ed09-43f8-9a0d-5ed4c9d91627"},"outputs":[{"name":"stdout","output_type":"stream","text":["전체 특성을 사용한 점수: 0.909\n","선택된 일부 특성을 사용한 점수: 0.937\n"]},{"name":"stderr","output_type":"stream","text":["A:\\Python\\Anaconda3.5\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","A:\\Python\\Anaconda3.5\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","\n","lr = #TODO   # 2진 분류 문제에 사용되는 알고리즘. ( 이예제는 SVC() 써도 됩니다.)\n","lr.#TODO(X_train, y_train)\n","print(\"전체 특성을 사용한 점수: {:.3f}\".format(#TODO(X_test, y_test)))\n","\n","lr = #TODO\n","lr.#TODO(X_train_selected, y_train)\n","print(\"선택된 일부 특성을 사용한 점수: {:.3f}\".format( #TODO(X_test_selected, y_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_je-4skPy8SH"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-1DSA5y0y8SI"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}